{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24f3b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from typing import TypedDict, List, Optional\n",
    "\n",
    "# LangGraph & LangChain ê´€ë ¨\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# ì„ë² ë”© & ìˆ˜í•™ ì—°ì‚° ê´€ë ¨\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# SLM (Llama.cpp) ê´€ë ¨\n",
    "from llama_cpp import Llama\n",
    "\n",
    "# =============================================================================\n",
    "# [ì„¤ì • ì˜ì—­] ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”.\n",
    "# =============================================================================\n",
    "\n",
    "# 1. ì‚¬ìš©í•  ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (ë‹¤ìš´ë¡œë“œ ë°›ì€ GGUF íŒŒì¼ ê²½ë¡œ)\n",
    "# ëª¨ë¸ì´ ì—†ë‹¤ë©´ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ USE_REAL_SLM = Falseë¡œ ì„¤ì •í•˜ë©´ ê°€ì§œ ì‘ë‹µìœ¼ë¡œ íë¦„ í™•ì¸ ê°€ëŠ¥\n",
    "MODEL_PATH = \"./models/Qwen2.5-Coder-3B-Instruct-Q4_K_M.gguf\" \n",
    "USE_REAL_SLM = False  # True: ì‹¤ì œ ëª¨ë¸ ì‚¬ìš©, False: ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ\n",
    "\n",
    "# 2. íƒ€ê²Ÿ ìŠ¤í‚¤ë§ˆ (ìš°ë¦¬ê°€ ë§¤í•‘í•˜ê³ ì í•˜ëŠ” í‘œì¤€ ì»¬ëŸ¼ë“¤)\n",
    "TARGET_SCHEMA = [\n",
    "    \"user_id\", \"user_name\", \"phone_number\", \"email_address\", \n",
    "    \"signup_date\", \"last_login\", \"is_active\", \"membership_level\",\n",
    "    \"total_purchase_amount\", \"shipping_address\"\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# [ì´ˆê¸°í™”] ëª¨ë¸ ë¡œë”© (ë©”ëª¨ë¦¬ì— ì˜¬ë¦¬ê¸°)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"â³ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘... (all-MiniLM-L6-v2)\")\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "target_embeddings = embed_model.encode(TARGET_SCHEMA) # íƒ€ê²Ÿ ìŠ¤í‚¤ë§ˆ ë¯¸ë¦¬ ë²¡í„°í™”\n",
    "print(\"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\")\n",
    "\n",
    "llm = None\n",
    "if USE_REAL_SLM:\n",
    "    print(f\"â³ SLM ëª¨ë¸ ë¡œë”© ì¤‘... ({MODEL_PATH})\")\n",
    "    try:\n",
    "        llm = Llama(\n",
    "            model_path=MODEL_PATH,\n",
    "            n_ctx=2048,      # ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° (ì…ë ¥ ê¸¸ì´ ì œí•œ)\n",
    "            n_threads=4,     # CPU ì½”ì–´ ìˆ˜ì— ë§ê²Œ ì¡°ì ˆ\n",
    "            verbose=False\n",
    "        )\n",
    "        print(\"âœ… SLM ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\\nğŸ‘‰ USE_REAL_SLM = Falseë¡œ ì „í™˜í•˜ì—¬ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\")\n",
    "        USE_REAL_SLM = False\n",
    "\n",
    "# =============================================================================\n",
    "# [LangGraph State] ë°ì´í„° íë¦„ ì •ì˜\n",
    "# =============================================================================\n",
    "class MappingState(TypedDict):\n",
    "    source_col: str          # ì…ë ¥: ë¶„ì„í•  ì†ŒìŠ¤ ì»¬ëŸ¼ëª…\n",
    "    sample_value: str        # ì…ë ¥: ì‹¤ì œ ë°ì´í„° ìƒ˜í”Œ (íŒíŠ¸ìš©)\n",
    "    candidates: List[str]    # ì¤‘ê°„ê°’: ì„ë² ë”©ì´ ì°¾ì•„ë‚¸ í›„ë³´êµ° (Top-k)\n",
    "    final_mapping: str       # ê²°ê³¼: SLMì´ ì„ íƒí•œ ìµœì¢… ì»¬ëŸ¼\n",
    "    reasoning: str           # ê²°ê³¼: SLMì˜ ì„ íƒ ì´ìœ \n",
    "\n",
    "# =============================================================================\n",
    "# [Node 1] Retriever (ì„ë² ë”© ê²€ìƒ‰ê¸°)\n",
    "# =============================================================================\n",
    "def retriever_node(state: MappingState):\n",
    "    source_col = state[\"source_col\"]\n",
    "    print(f\"\\n--- [Step 1] Retriever ì‹¤í–‰: '{source_col}' ê²€ìƒ‰ ---\")\n",
    "    \n",
    "    # 1. ì†ŒìŠ¤ ì»¬ëŸ¼ ë²¡í„°í™”\n",
    "    source_vec = embed_model.encode([source_col])\n",
    "    \n",
    "    # 2. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    similarities = cosine_similarity(source_vec, target_embeddings)[0]\n",
    "    \n",
    "    # 3. ìƒìœ„ 3ê°œ í›„ë³´ ì¶”ì¶œ (Top-3)\n",
    "    # argsortëŠ” ì˜¤ë¦„ì°¨ìˆœì´ë¯€ë¡œ ë’¤ì§‘ì–´ì„œ í° ê°’ë¶€í„° ê°€ì ¸ì˜´\n",
    "    top_k_indices = np.argsort(similarities)[-3:][::-1]\n",
    "    candidates = [TARGET_SCHEMA[i] for i in top_k_indices]\n",
    "    \n",
    "    print(f\"   ğŸ‘‰ ìœ ì‚¬ë„ ê¸°ë°˜ í›„ë³´êµ°: {candidates}\")\n",
    "    return {\"candidates\": candidates}\n",
    "\n",
    "# =============================================================================\n",
    "# [Node 2] Reasoner (SLM ì¶”ë¡ ê¸°)\n",
    "# =============================================================================\n",
    "def slm_reasoning_node(state: MappingState):\n",
    "    source_col = state[\"source_col\"]\n",
    "    sample_value = state[\"sample_value\"]\n",
    "    candidates = state[\"candidates\"]\n",
    "    \n",
    "    print(f\"\\n--- [Step 2] SLM ì¶”ë¡  ì‹¤í–‰ (Candidate Selection) ---\")\n",
    "\n",
    "    # 1. í”„ë¡¬í”„íŠ¸ ì‘ì„± (Few-shot & Context ì œê³µ)\n",
    "    prompt = f\"\"\"<|im_start|>system\n",
    "You are a Data Engineer expert in Schema Mapping.\n",
    "Select the most appropriate Target Column from the Candidates list that matches the Source Column and Sample Value.\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "[Input Data]\n",
    "- Source Column: \"{source_col}\"\n",
    "- Sample Data: \"{sample_value}\"\n",
    "- Candidates: {candidates}\n",
    "\n",
    "[Instruction]\n",
    "Analyze the meaning of the Source Column and the pattern of the Sample Data.\n",
    "Then, choose ONE target column from the candidates.\n",
    "If none match perfectly, choose the closest one.\n",
    "\n",
    "Output format should be JSON:\n",
    "{{\n",
    "    \"selected_column\": \"target_column_name\",\n",
    "    \"reason\": \"short explanation\"\n",
    "}}\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "    \n",
    "    # 2. ëª¨ë¸ ì¶”ë¡  (Inference)\n",
    "    if USE_REAL_SLM and llm:\n",
    "        # ì‹¤ì œ SLM í˜¸ì¶œ\n",
    "        output = llm(\n",
    "            prompt,\n",
    "            max_tokens=200,\n",
    "            stop=[\"<|im_end|>\"],\n",
    "            temperature=0.1, # ì¼ê´€ëœ ë‹µë³€ì„ ìœ„í•´ ë‚®ì¶¤\n",
    "            echo=False\n",
    "        )\n",
    "        response_text = output['choices'][0]['text'].strip()\n",
    "    else:\n",
    "        # [ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ] ëª¨ë¸ íŒŒì¼ì´ ì—†ì„ ë•Œ ë¡œì§ í™•ì¸ìš© ê°€ì§œ ì‘ë‹µ\n",
    "        print(\"   âš ï¸ (Simulation Mode) SLM í˜¸ì¶œì„ í‰ë‚´ëƒ…ë‹ˆë‹¤.\")\n",
    "        if \"hp\" in source_col or \"010\" in sample_value:\n",
    "            response_text = '{\"selected_column\": \"phone_number\", \"reason\": \"Sample data is a Korean mobile number format.\"}'\n",
    "        else:\n",
    "            response_text = f'{{\"selected_column\": \"{candidates[0]}\", \"reason\": \"Highest similarity.\"}}'\n",
    "\n",
    "    # 3. ê²°ê³¼ íŒŒì‹± (JSON)\n",
    "    try:\n",
    "        # ê°€ë” ëª¨ë¸ì´ ì½”ë“œ ë¸”ë¡(```json ... ```)ì„ ë„£ì„ ìˆ˜ ìˆì–´ ì œê±° ì²˜ë¦¬\n",
    "        cleaned_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        result_json = json.loads(cleaned_text)\n",
    "        \n",
    "        final_col = result_json.get(\"selected_column\", \"Unknown\")\n",
    "        reason = result_json.get(\"reason\", \"No reason provided\")\n",
    "        \n",
    "    except json.JSONDecodeError:\n",
    "        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜\n",
    "        final_col = \"Parsing Error\"\n",
    "        reason = response_text\n",
    "\n",
    "    print(f\"   ğŸ¤– SLMì˜ ì„ íƒ: {final_col}\")\n",
    "    print(f\"   ğŸ’¡ ì´ìœ : {reason}\")\n",
    "\n",
    "    return {\"final_mapping\": final_col, \"reasoning\": reason}\n",
    "\n",
    "# =============================================================================\n",
    "# [Graph Construction] íŒŒì´í”„ë¼ì¸ ì¡°ë¦½\n",
    "# =============================================================================\n",
    "workflow = StateGraph(MappingState)\n",
    "\n",
    "# ë…¸ë“œ ë“±ë¡\n",
    "workflow.add_node(\"retriever\", retriever_node)\n",
    "workflow.add_node(\"reasoner\", slm_reasoning_node)\n",
    "\n",
    "# ì—£ì§€ ì—°ê²° (ìˆœì„œ: Start -> Retriever -> Reasoner -> End)\n",
    "workflow.set_entry_point(\"retriever\")\n",
    "workflow.add_edge(\"retriever\", \"reasoner\")\n",
    "workflow.add_edge(\"reasoner\", END)\n",
    "\n",
    "# ì»´íŒŒì¼\n",
    "app = workflow.compile()\n",
    "\n",
    "# =============================================================================\n",
    "# [Execution] í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 1: ì• ë§¤í•œ ì•½ì–´ ì»¬ëŸ¼\n",
    "    input_data = {\n",
    "        \"source_col\": \"m_hp\",         # ë‹¨ìˆœíˆ 'hp'ë§Œ ë³´ë©´ home phoneì¸ì§€ í—·ê°ˆë¦¼\n",
    "        \"sample_value\": \"010-1234-5678\" # ë°ì´í„°ëŠ” ëª…í™•íˆ íœ´ëŒ€í° ë²ˆí˜¸\n",
    "    }\n",
    "\n",
    "    print(\"ğŸš€ [Start] ìŠ¤í‚¤ë§ˆ ë§¤í•‘ ì—ì´ì „íŠ¸ ì‹œì‘\")\n",
    "    result = app.invoke(input_data)\n",
    "    \n",
    "    print(\"\\n============================================\")\n",
    "    print(f\"ğŸ¯ ìµœì¢… ë§¤í•‘ ê²°ê³¼: [{input_data['source_col']}] -> [{result['final_mapping']}]\")\n",
    "    print(f\"ğŸ“ ì¶”ë¡  ê·¼ê±°: {result['reasoning']}\")\n",
    "    print(\"============================================\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
