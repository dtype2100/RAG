{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://api.python.langchain.com/en/latest/community/chat_models/langchain_community.chat_models.llamacpp.ChatLlamaCpp.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from langchain_community.chat_models import ChatLlamaCpp\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# RAG 체인 구성\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\n",
    "    dotenv_path = \"../.env\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 시스템을 위한 LLM 설정 (KV 캐시 최적화 포함)\n",
    "llm = ChatLlamaCpp(\n",
    "    temperature=0.1,  # RAG에서는 더 일관된 답변을 위해 낮은 temperature 사용\n",
    "    model_path=config[\"EXAONE-3.5-2.4B-Instruct-Q4_K_M.gguf\"],\n",
    "    n_ctx=16384,  # 컨텍스트 크기를 적절히 조정 (32768은 메모리 부담이 큼)\n",
    "    n_gpu_layers=8,\n",
    "    n_batch=32,  # KV 캐시 최적화를 위해 더 작은 배치 크기\n",
    "    max_tokens=512,  # 더 긴 답변을 위해 토큰 수 증가\n",
    "    n_threads=multiprocessing.cpu_count() - 1,\n",
    "    repeat_penalty=1.1,  # RAG에서는 적당한 반복 패널티\n",
    "    top_p=0.9,  # RAG에서는 더 높은 top_p로 다양한 답변 생성\n",
    "    verbose=False,  # RAG에서는 verbose 비활성화로 출력 정리\n",
    "    callback_manager=callback_manager,\n",
    "    \n",
    "    # KV 캐시 최적화를 위한 설정들\n",
    "    use_mlock=True,  # 메모리 잠금으로 성능 향상\n",
    "    use_mmap=True,   # 메모리 맵핑 사용\n",
    "    \n",
    "    # 추가적인 KV 캐시 관련 설정들\n",
    "    # n_keep=-1,     # 모든 토큰을 캐시에 유지 (선택사항)\n",
    "    # rope_scaling_type=1,  # RoPE 스케일링 (긴 컨텍스트용)\n",
    "    # rope_freq_base=10000,  # RoPE 주파수 기본값\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 분할기 설정\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# 샘플 문서 데이터 (실제로는 파일에서 로드)\n",
    "documents = [\n",
    "    \"인공지능(AI)은 컴퓨터 시스템이 인간의 지능을 모방하여 학습하고 추론할 수 있도록 하는 기술입니다.\",\n",
    "    \"머신러닝은 AI의 한 분야로, 데이터로부터 패턴을 학습하여 예측이나 분류를 수행합니다.\",\n",
    "    \"딥러닝은 신경망을 사용하여 복잡한 패턴을 학습하는 머신러닝의 하위 분야입니다.\",\n",
    "    \"자연어처리(NLP)는 인간의 언어를 컴퓨터가 이해하고 처리할 수 있도록 하는 AI 기술입니다.\",\n",
    "    \"컴퓨터 비전은 이미지나 비디오에서 의미 있는 정보를 추출하는 AI 분야입니다.\"\n",
    "]\n",
    "\n",
    "# 문서 분할\n",
    "texts = text_splitter.create_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델 설정\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=config[\"multilingual-e5-small-ko\"],\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 스토어 생성\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 체인 생성\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    return_source_documents=True,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 구성\n",
    "question = \"머신러닝에 대해 알려줘\"\n",
    "prompt = f\"<|im_start|>system\\n당신은 도움이 되는 AI 어시스턴트입니다. 질문에 대해 3문장 정도 정확하고 유용한 답변을 제공해주세요.<|im_end|>\\n<|im_start|>user\\n{question}<|im_end|>\\n<|im_start|>assistant\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "머신러닝은 컴퓨터 시스템이 데이터로부터 학습하여 패턴을 인식하고 예측 또는 결정을 내리는 기술입니다. 이 과정에서 알고리즘은 반복적인 훈련을 통해 성능을 향상시킵니다. 주요 응용 분야로는 추천 시스템, 이미지 및 음성 인식, 자연어 처리 등이 있습니다."
     ]
    }
   ],
   "source": [
    "response = qa_chain.invoke(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
