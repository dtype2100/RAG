{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f15c495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from llama_cpp import Llama\n",
    "\n",
    "# âœ… [NEW] LangChainì˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸°\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# =============================================================================\n",
    "# [ì„¤ì •] ëª¨ë¸ ë° í™˜ê²½\n",
    "# =============================================================================\n",
    "MODEL_PATH = \"./models/Qwen2.5-Coder-3B-Instruct-Q4_K_M.gguf\"\n",
    "USE_REAL_SLM = False  # í…ŒìŠ¤íŠ¸ ì‹œ False, ì‹¤ì œ êµ¬ë™ ì‹œ True\n",
    "\n",
    "TARGET_SCHEMA = [\n",
    "    \"user_id\", \"user_name\", \"phone_number\", \"email_address\", \n",
    "    \"signup_date\", \"last_login\", \"is_active\", \"shipping_address\"\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# [Prompt Engineering] í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ (ì—¬ê¸°ê°€ í•µì‹¬!)\n",
    "# =============================================================================\n",
    "# íŒŒì´ì¬ ì½”ë“œ ì•ˆì— ë¬¸ìì—´ì„ ìˆ¨ê¸°ì§€ ì•Šê³ , ì „ì—­ ë³€ìˆ˜ë¡œ ë¹¼ì„œ ê´€ë¦¬í•©ë‹ˆë‹¤.\n",
    "# Qwen/Llama3ì˜ í¬ë§·(<|im_start|>)ì„ ëª…ì‹œì ìœ¼ë¡œ ì§€ì¼œì¤ë‹ˆë‹¤.\n",
    "\n",
    "mapping_template_str = \"\"\"<|im_start|>system\n",
    "You are a Data Engineer expert in Schema Mapping.\n",
    "Select the best Target Column from the Candidates that matches the Source Column.\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "[Input Data]\n",
    "- Source Column: \"{source_col}\"\n",
    "- Sample Data: \"{sample_value}\"\n",
    "- Candidates: {candidates}\n",
    "\n",
    "[Instruction]\n",
    "Analyze the meaning of the Source Column and the pattern of the Sample Data.\n",
    "Choose ONE target column. Return ONLY JSON format.\n",
    "\n",
    "Example Output:\n",
    "{{\n",
    "    \"selected_column\": \"target_column_name\",\n",
    "    \"reason\": \"short explanation\"\n",
    "}}\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "# LangChain PromptTemplate ê°ì²´ ìƒì„±\n",
    "MAPPING_PROMPT = PromptTemplate(\n",
    "    template=mapping_template_str,\n",
    "    input_variables=[\"source_col\", \"sample_value\", \"candidates\"]\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# [ì´ˆê¸°í™”] ëª¨ë¸ ë¡œë”©\n",
    "# =============================================================================\n",
    "print(\"â³ Loading Models...\")\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "target_embeddings = embed_model.encode(TARGET_SCHEMA)\n",
    "\n",
    "llm = None\n",
    "if USE_REAL_SLM:\n",
    "    llm = Llama(model_path=MODEL_PATH, n_ctx=2048, verbose=False)\n",
    "\n",
    "# =============================================================================\n",
    "# [Node Logic]\n",
    "# =============================================================================\n",
    "class MappingState(TypedDict):\n",
    "    source_col: str\n",
    "    sample_value: str\n",
    "    candidates: List[str]\n",
    "    final_mapping: str\n",
    "    reasoning: str\n",
    "\n",
    "def retriever_node(state: MappingState):\n",
    "    # (ì´ì „ê³¼ ë™ì¼: ì„ë² ë”© ê²€ìƒ‰)\n",
    "    source_vec = embed_model.encode([state[\"source_col\"]])\n",
    "    similarities = cosine_similarity(source_vec, target_embeddings)[0]\n",
    "    top_k_indices = np.argsort(similarities)[-3:][::-1]\n",
    "    candidates = [TARGET_SCHEMA[i] for i in top_k_indices]\n",
    "    \n",
    "    print(f\"ğŸ” [Retriever] í›„ë³´êµ° ì¶”ì¶œ: {candidates}\")\n",
    "    return {\"candidates\": candidates}\n",
    "\n",
    "def slm_reasoning_node(state: MappingState):\n",
    "    \"\"\"\n",
    "    PromptTemplateì„ ì‚¬ìš©í•˜ì—¬ ì½”ë“œê°€ í›¨ì”¬ ê¹”ë”í•´ì§„ ë…¸ë“œì…ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ§  [SLM] ì¶”ë¡  ì‹œì‘...\")\n",
    "\n",
    "    # âœ… [NEW] í…œí”Œë¦¿ì— ë°ì´í„° ì£¼ì… (Validation ê¸°ëŠ¥ í¬í•¨)\n",
    "    # ë³€ìˆ˜ê°€ ëˆ„ë½ë˜ë©´ ì—¬ê¸°ì„œ ë°”ë¡œ ì—ëŸ¬ë¥¼ ë‚´ì£¼ë¯€ë¡œ ë””ë²„ê¹…ì´ í¸í•¨\n",
    "    final_prompt = MAPPING_PROMPT.format(\n",
    "        source_col=state[\"source_col\"],\n",
    "        sample_value=state[\"sample_value\"],\n",
    "        candidates=state[\"candidates\"]\n",
    "    )\n",
    "    \n",
    "    # ì‹¤ì œ ì¶”ë¡ \n",
    "    if USE_REAL_SLM and llm:\n",
    "        output = llm(final_prompt, max_tokens=200, stop=[\"<|im_end|>\"], echo=False)\n",
    "        response_text = output['choices'][0]['text'].strip()\n",
    "    else:\n",
    "        # ì‹œë®¬ë ˆì´ì…˜\n",
    "        response_text = '{\"selected_column\": \"phone_number\", \"reason\": \"Simulated Result\"}'\n",
    "\n",
    "    # íŒŒì‹± ë¡œì§ (Robustness ìœ ì§€)\n",
    "    try:\n",
    "        cleaned_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        result_json = json.loads(cleaned_text)\n",
    "        final_col = result_json.get(\"selected_column\", \"Unknown\")\n",
    "        reason = result_json.get(\"reason\", \"No reason\")\n",
    "    except json.JSONDecodeError:\n",
    "        final_col = \"Error\"\n",
    "        reason = response_text\n",
    "\n",
    "    return {\"final_mapping\": final_col, \"reasoning\": reason}\n",
    "\n",
    "# =============================================================================\n",
    "# [Graph]\n",
    "# =============================================================================\n",
    "workflow = StateGraph(MappingState)\n",
    "workflow.add_node(\"retriever\", retriever_node)\n",
    "workflow.add_node(\"reasoner\", slm_reasoning_node)\n",
    "workflow.set_entry_point(\"retriever\")\n",
    "workflow.add_edge(\"retriever\", \"reasoner\")\n",
    "workflow.add_edge(\"reasoner\", END)\n",
    "app = workflow.compile()\n",
    "\n",
    "# =============================================================================\n",
    "# [Test]\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    result = app.invoke({\n",
    "        \"source_col\": \"m_hp\", \n",
    "        \"sample_value\": \"010-1234-5678\"\n",
    "    })\n",
    "    print(f\"\\nâœ… Result: {result['final_mapping']} ({result['reasoning']})\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
