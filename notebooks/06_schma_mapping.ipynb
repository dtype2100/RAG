{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ee24eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jw160\\project\\RAG\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘... (all-MiniLM-L6-v2)\n",
      "âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\n",
      "ğŸš€ [Start] ìŠ¤í‚¤ë§ˆ ë§¤í•‘ ì—ì´ì „íŠ¸ ì‹œì‘\n",
      "\n",
      "--- [Step 1] Retriever ì‹¤í–‰: 'm_hp' ê²€ìƒ‰ ---\n",
      "   ğŸ‘‰ ìœ ì‚¬ë„ ê¸°ë°˜ í›„ë³´êµ°: ['user_name', 'total_purchase_amount', 'phone_number']\n",
      "\n",
      "--- [Step 2] SLM ì¶”ë¡  ì‹¤í–‰ (Candidate Selection) ---\n",
      "   âš ï¸ (Simulation Mode) SLM í˜¸ì¶œì„ í‰ë‚´ëƒ…ë‹ˆë‹¤.\n",
      "   ğŸ¤– SLMì˜ ì„ íƒ: phone_number\n",
      "   ğŸ’¡ ì´ìœ : Sample data is a Korean mobile number format.\n",
      "\n",
      "============================================\n",
      "ğŸ¯ ìµœì¢… ë§¤í•‘ ê²°ê³¼: [m_hp] -> [phone_number]\n",
      "ğŸ“ ì¶”ë¡  ê·¼ê±°: Sample data is a Korean mobile number format.\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from typing import TypedDict, List, Optional\n",
    "\n",
    "# LangGraph & LangChain ê´€ë ¨\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# ì„ë² ë”© & ìˆ˜í•™ ì—°ì‚° ê´€ë ¨\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain.chat_models import init_chat_model\n",
    "# SLM (Llama.cpp) ê´€ë ¨\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# [ì„¤ì • ì˜ì—­] ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”.\n",
    "# =============================================================================\n",
    "\n",
    "# 1. ì‚¬ìš©í•  ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (ë‹¤ìš´ë¡œë“œ ë°›ì€ GGUF íŒŒì¼ ê²½ë¡œ)\n",
    "# ëª¨ë¸ì´ ì—†ë‹¤ë©´ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ USE_REAL_SLM = Falseë¡œ ì„¤ì •í•˜ë©´ ê°€ì§œ ì‘ë‹µìœ¼ë¡œ íë¦„ í™•ì¸ ê°€ëŠ¥\n",
    "MODEL_PATH = \"./models/Qwen2.5-Coder-3B-Instruct-Q4_K_M.gguf\" \n",
    "USE_REAL_SLM = False  # True: ì‹¤ì œ ëª¨ë¸ ì‚¬ìš©, False: ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ\n",
    "\n",
    "# 2. íƒ€ê²Ÿ ìŠ¤í‚¤ë§ˆ (ìš°ë¦¬ê°€ ë§¤í•‘í•˜ê³ ì í•˜ëŠ” í‘œì¤€ ì»¬ëŸ¼ë“¤)\n",
    "TARGET_SCHEMA = [\n",
    "    \"user_id\", \"user_name\", \"phone_number\", \"email_address\", \n",
    "    \"signup_date\", \"last_login\", \"is_active\", \"membership_level\",\n",
    "    \"total_purchase_amount\", \"shipping_address\"\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# [ì´ˆê¸°í™”] ëª¨ë¸ ë¡œë”© (ë©”ëª¨ë¦¬ì— ì˜¬ë¦¬ê¸°)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"â³ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘... (all-MiniLM-L6-v2)\")\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "target_embeddings = embed_model.encode(TARGET_SCHEMA) # íƒ€ê²Ÿ ìŠ¤í‚¤ë§ˆ ë¯¸ë¦¬ ë²¡í„°í™”\n",
    "print(\"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\")\n",
    "\n",
    "llm = None\n",
    "if USE_REAL_SLM:\n",
    "    print(f\"â³ SLM ëª¨ë¸ ë¡œë”© ì¤‘... ({MODEL_PATH})\")\n",
    "    try:\n",
    "        llm =init_chat_model(\n",
    "                \"smollm2\",\n",
    "                model_provider=\"ollama\",\n",
    "                base_url=\"http://localhost:11434\",\n",
    "                temperature=0,\n",
    "                max_tokens=126,\n",
    "                model_kwargs={\n",
    "                \"num_predict\": 50  # Ollama ì „ìš© íŒŒë¼ë¯¸í„°\n",
    "                }\n",
    "            )\n",
    "        print(\"âœ… SLM ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\\nğŸ‘‰ USE_REAL_SLM = Falseë¡œ ì „í™˜í•˜ì—¬ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\")\n",
    "        USE_REAL_SLM = False\n",
    "\n",
    "# =============================================================================\n",
    "# [LangGraph State] ë°ì´í„° íë¦„ ì •ì˜\n",
    "# =============================================================================\n",
    "class MappingState(TypedDict):\n",
    "    source_col: str          # ì…ë ¥: ë¶„ì„í•  ì†ŒìŠ¤ ì»¬ëŸ¼ëª…\n",
    "    sample_value: str        # ì…ë ¥: ì‹¤ì œ ë°ì´í„° ìƒ˜í”Œ (íŒíŠ¸ìš©)\n",
    "    candidates: List[str]    # ì¤‘ê°„ê°’: ì„ë² ë”©ì´ ì°¾ì•„ë‚¸ í›„ë³´êµ° (Top-k)\n",
    "    final_mapping: str       # ê²°ê³¼: SLMì´ ì„ íƒí•œ ìµœì¢… ì»¬ëŸ¼\n",
    "    reasoning: str           # ê²°ê³¼: SLMì˜ ì„ íƒ ì´ìœ \n",
    "\n",
    "# =============================================================================\n",
    "# [Node 1] Retriever (ì„ë² ë”© ê²€ìƒ‰ê¸°)\n",
    "# =============================================================================\n",
    "def retriever_node(state: MappingState):\n",
    "    source_col = state[\"source_col\"]\n",
    "    print(f\"\\n--- [Step 1] Retriever ì‹¤í–‰: '{source_col}' ê²€ìƒ‰ ---\")\n",
    "    \n",
    "    # 1. ì†ŒìŠ¤ ì»¬ëŸ¼ ë²¡í„°í™”\n",
    "    source_vec = embed_model.encode([source_col])\n",
    "    \n",
    "    # 2. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    similarities = cosine_similarity(source_vec, target_embeddings)[0]\n",
    "    \n",
    "    # 3. ìƒìœ„ 3ê°œ í›„ë³´ ì¶”ì¶œ (Top-3)\n",
    "    # argsortëŠ” ì˜¤ë¦„ì°¨ìˆœì´ë¯€ë¡œ ë’¤ì§‘ì–´ì„œ í° ê°’ë¶€í„° ê°€ì ¸ì˜´\n",
    "    top_k_indices = np.argsort(similarities)[-3:][::-1]\n",
    "    candidates = [TARGET_SCHEMA[i] for i in top_k_indices]\n",
    "    \n",
    "    print(f\"   ğŸ‘‰ ìœ ì‚¬ë„ ê¸°ë°˜ í›„ë³´êµ°: {candidates}\")\n",
    "    return {\"candidates\": candidates}\n",
    "\n",
    "# =============================================================================\n",
    "# [Node 2] Reasoner (SLM ì¶”ë¡ ê¸°)\n",
    "# =============================================================================\n",
    "def slm_reasoning_node(state: MappingState):\n",
    "    source_col = state[\"source_col\"]\n",
    "    sample_value = state[\"sample_value\"]\n",
    "    candidates = state[\"candidates\"]\n",
    "    \n",
    "    print(f\"\\n--- [Step 2] SLM ì¶”ë¡  ì‹¤í–‰ (Candidate Selection) ---\")\n",
    "\n",
    "    # 1. í”„ë¡¬í”„íŠ¸ ì‘ì„± (Few-shot & Context ì œê³µ)\n",
    "    prompt = f\"\"\"<|im_start|>system\n",
    "You are a Data Engineer expert in Schema Mapping.\n",
    "Select the most appropriate Target Column from the Candidates list that matches the Source Column and Sample Value.\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "[Input Data]\n",
    "- Source Column: \"{source_col}\"\n",
    "- Sample Data: \"{sample_value}\"\n",
    "- Candidates: {candidates}\n",
    "\n",
    "[Instruction]\n",
    "Analyze the meaning of the Source Column and the pattern of the Sample Data.\n",
    "Then, choose ONE target column from the candidates.\n",
    "If none match perfectly, choose the closest one.\n",
    "\n",
    "Output format should be JSON:\n",
    "{{\n",
    "    \"selected_column\": \"target_column_name\",\n",
    "    \"reason\": \"short explanation\"\n",
    "}}\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "    \n",
    "    # 2. ëª¨ë¸ ì¶”ë¡  (Inference)\n",
    "    if USE_REAL_SLM and llm:\n",
    "        # ì‹¤ì œ SLM í˜¸ì¶œ\n",
    "        output = llm(\n",
    "            prompt,\n",
    "            max_tokens=200,\n",
    "            stop=[\"<|im_end|>\"],\n",
    "            temperature=0.1, # ì¼ê´€ëœ ë‹µë³€ì„ ìœ„í•´ ë‚®ì¶¤\n",
    "            echo=False\n",
    "        )\n",
    "        response_text = output['choices'][0]['text'].strip()\n",
    "    else:\n",
    "        # [ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ] ëª¨ë¸ íŒŒì¼ì´ ì—†ì„ ë•Œ ë¡œì§ í™•ì¸ìš© ê°€ì§œ ì‘ë‹µ\n",
    "        print(\"   âš ï¸ (Simulation Mode) SLM í˜¸ì¶œì„ í‰ë‚´ëƒ…ë‹ˆë‹¤.\")\n",
    "        if \"hp\" in source_col or \"010\" in sample_value:\n",
    "            response_text = '{\"selected_column\": \"phone_number\", \"reason\": \"Sample data is a Korean mobile number format.\"}'\n",
    "        else:\n",
    "            response_text = f'{{\"selected_column\": \"{candidates[0]}\", \"reason\": \"Highest similarity.\"}}'\n",
    "\n",
    "    # 3. ê²°ê³¼ íŒŒì‹± (JSON)\n",
    "    try:\n",
    "        # ê°€ë” ëª¨ë¸ì´ ì½”ë“œ ë¸”ë¡(```json ... ```)ì„ ë„£ì„ ìˆ˜ ìˆì–´ ì œê±° ì²˜ë¦¬\n",
    "        cleaned_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        result_json = json.loads(cleaned_text)\n",
    "        \n",
    "        final_col = result_json.get(\"selected_column\", \"Unknown\")\n",
    "        reason = result_json.get(\"reason\", \"No reason provided\")\n",
    "        \n",
    "    except json.JSONDecodeError:\n",
    "        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜\n",
    "        final_col = \"Parsing Error\"\n",
    "        reason = response_text\n",
    "\n",
    "    print(f\"   ğŸ¤– SLMì˜ ì„ íƒ: {final_col}\")\n",
    "    print(f\"   ğŸ’¡ ì´ìœ : {reason}\")\n",
    "\n",
    "    return {\"final_mapping\": final_col, \"reasoning\": reason}\n",
    "\n",
    "# =============================================================================\n",
    "# [Graph Construction] íŒŒì´í”„ë¼ì¸ ì¡°ë¦½\n",
    "# =============================================================================\n",
    "workflow = StateGraph(MappingState)\n",
    "\n",
    "# ë…¸ë“œ ë“±ë¡\n",
    "workflow.add_node(\"retriever\", retriever_node)\n",
    "workflow.add_node(\"reasoner\", slm_reasoning_node)\n",
    "\n",
    "# ì—£ì§€ ì—°ê²° (ìˆœì„œ: Start -> Retriever -> Reasoner -> End)\n",
    "workflow.set_entry_point(\"retriever\")\n",
    "workflow.add_edge(\"retriever\", \"reasoner\")\n",
    "workflow.add_edge(\"reasoner\", END)\n",
    "\n",
    "# ì»´íŒŒì¼\n",
    "app = workflow.compile()\n",
    "\n",
    "# =============================================================================\n",
    "# [Execution] í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 1: ì• ë§¤í•œ ì•½ì–´ ì»¬ëŸ¼\n",
    "    input_data = {\n",
    "        \"source_col\": \"m_hp\",         # ë‹¨ìˆœíˆ 'hp'ë§Œ ë³´ë©´ home phoneì¸ì§€ í—·ê°ˆë¦¼\n",
    "        \"sample_value\": \"010-1234-5678\" # ë°ì´í„°ëŠ” ëª…í™•íˆ íœ´ëŒ€í° ë²ˆí˜¸\n",
    "    }\n",
    "\n",
    "    print(\"ğŸš€ [Start] ìŠ¤í‚¤ë§ˆ ë§¤í•‘ ì—ì´ì „íŠ¸ ì‹œì‘\")\n",
    "    result = app.invoke(input_data)\n",
    "    \n",
    "    print(\"\\n============================================\")\n",
    "    print(f\"ğŸ¯ ìµœì¢… ë§¤í•‘ ê²°ê³¼: [{input_data['source_col']}] -> [{result['final_mapping']}]\")\n",
    "    print(f\"ğŸ“ ì¶”ë¡  ê·¼ê±°: {result['reasoning']}\")\n",
    "    print(\"============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f91c521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ [Start] ìŠ¤í‚¤ë§ˆ ë§¤í•‘ ì—ì´ì „íŠ¸ ì‹œì‘\n",
      "\n",
      "--- [Step 1] Retriever ì‹¤í–‰: 'name' ê²€ìƒ‰ ---\n",
      "   ğŸ‘‰ ìœ ì‚¬ë„ ê¸°ë°˜ í›„ë³´êµ°: ['user_name', 'email_address', 'phone_number']\n",
      "\n",
      "--- [Step 2] SLM ì¶”ë¡  ì‹¤í–‰ (Candidate Selection) ---\n",
      "   âš ï¸ (Simulation Mode) SLM í˜¸ì¶œì„ í‰ë‚´ëƒ…ë‹ˆë‹¤.\n",
      "   ğŸ¤– SLMì˜ ì„ íƒ: user_name\n",
      "   ğŸ’¡ ì´ìœ : Highest similarity.\n",
      "\n",
      "============================================\n",
      "ğŸ¯ ìµœì¢… ë§¤í•‘ ê²°ê³¼: [name] -> [user_name]\n",
      "ğŸ“ ì¶”ë¡  ê·¼ê±°: Highest similarity.\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"source_col\": \"name\",         # ë‹¨ìˆœíˆ 'hp'ë§Œ ë³´ë©´ home phoneì¸ì§€ í—·ê°ˆë¦¼\n",
    "    \"sample_value\": \"í™ê¸¸ë™\" # ë°ì´í„°ëŠ” ëª…í™•íˆ íœ´ëŒ€í° ë²ˆí˜¸\n",
    "}\n",
    "\n",
    "print(\"ğŸš€ [Start] ìŠ¤í‚¤ë§ˆ ë§¤í•‘ ì—ì´ì „íŠ¸ ì‹œì‘\")\n",
    "result = app.invoke(input_data)\n",
    "\n",
    "print(\"\\n============================================\")\n",
    "print(f\"ğŸ¯ ìµœì¢… ë§¤í•‘ ê²°ê³¼: [{input_data['source_col']}] -> [{result['final_mapping']}]\")\n",
    "print(f\"ğŸ“ ì¶”ë¡  ê·¼ê±°: {result['reasoning']}\")\n",
    "print(\"============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0dfe10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
